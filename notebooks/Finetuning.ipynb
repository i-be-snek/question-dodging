{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c367521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# \n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.utils import send_example_telemetry\n",
    "# send_example_telemetry(\"language_modeling_notebook_finetuning_nli\", framework=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380dc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of problems with the gpu memory\n",
    "def clear_gpu_mem(): \n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()\n",
    "\n",
    "clear_gpu_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ad57a-ef76-4c9c-828e-918d9afe2ffc",
   "metadata": {
    "id": "7c9ad57a-ef76-4c9c-828e-918d9afe2ffc"
   },
   "source": [
    "#### Load finetuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42bee734-9884-4fd1-ad70-decb33927b5f",
   "metadata": {
    "id": "42bee734-9884-4fd1-ad70-decb33927b5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:15:13.158499: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-19 15:15:13.186034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-19 15:15:13.186059: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-19 15:15:13.186076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-19 15:15:13.191119: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-19 15:15:13.764458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # for more convenient data splitting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, DatasetDict # to create Dataset objects\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "import mlflow # for ml tracking\n",
    "\n",
    "from string import Template # to template the premise and hypothesis for the NLI task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91a647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"colheader_justify\", \"left\")\n",
    "\n",
    "path = \"../data/processed\"\n",
    "dataset_files = [\"question_avoidance_preprocessed_dataset.parquet\"]\n",
    "finetuning_datasets = {}\n",
    "for i in dataset_files:\n",
    "    finetuning_datasets[i.split(\".parquet\")[0]] = pd.read_parquet(f\"{path}/{i}\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>I'm a young guy with two weeks off and about $1,000 to spend, so I'm wondering what experiences have stuck with people most. What was your best adventure/program/vacation?</td>\n",
       "      <td>The first time I went to an actually nice beach after growing up going to the beaches on the Gulf of Mexico.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>It does not take Sherlock Holmes to work out that if a rich father employs accountants or financial advisers to produce figures that indicate that he does not have the financial wherewithal to pay maintenance to his children , there is a possibility that some fiddles will be going on . Where financial advisers and accountants are employed to suggest that a father can not afford to pay maintenance for his children , surely there should be another system to check whether something may be wrong ?</td>\n",
       "      <td>Family insecurity is now as important as economic insecurity as a force for poverty and disadvantage . We have new policies on child support , which we aim to implement as soon as possible . We are driving up the rate of payment—in terms of the cash that is now due , some 70 per cent . or more of maintenance is now paid . There remain some non - resident parents or absent fathers , however—perhaps 30 per cent.—who are not paying maintenance . The purpose of our new reforms is to spend less time on complicated assessment , in a move towards simplicity , and more time on enforcement . It is crucial that we undertake that as soon as possible .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>If the Home Secretary is not willing to consider handing the police in London over to an elected authority , will he consider handing them over to at least a partly elected authority , in line with the discussions going on about other powers in the context of the GLC abolition Bill being considered in the other place between Ministers and Conservative peers ?</td>\n",
       "      <td>Since returning from the United States , I have tried to play a full part in alerting the public to the problem of the glut of cocaine available in South America and likely to be diverted from the American to the British market . Already , a considerable response has been evident , notably in the formation of two customs teams specifically to deal with cocaine . Cocaine seizures this year are much higher than they were last year . That is a measure of success , but we intend to be diligent on this vital topic .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Do you think you're enjoying tennis again? It seemed after you won the French Open there was a lot of pressure; last year you had a tough match here. Are you feeling happier?</td>\n",
       "      <td>I think, yes, yes. At least until beginning of 2013 until now I didn't waste the if I have match point, I didn't win the match, so... I think it's very tough, you know, because when I was playing Cirstea in Rod Laver, I was thinking about the match last year. Something you couldn't forget. Always in your mind, yeah.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>As the Gray report refers to major procurement activities , will the Minister tell me , and the House , what recent discussions he has had with commanders on the ground about the effectiveness of personal protection equipment for our troops in theatre - such as the Stourbridge war hero , 19-year - old Michelle Norris , who risked her life and was the first woman to gain the military cross for her work ?</td>\n",
       "      <td>Of course I noticed that rather startling figure when I read the Gray report myself . The right hon Gentleman , who has obviously read the report , will also have noticed that there is no evidential basis for that statement anywhere in it , nor is there an evidential basis for it anywhere else that I have ever come across . The very fact that the figure ranges between £ 1 billion and more than £ 2 billion shows , I think , how imprecise that statement inevitably is .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \\\n",
       "279                                                                                                                                                                                                                                                                                                                                         I'm a young guy with two weeks off and about $1,000 to spend, so I'm wondering what experiences have stuck with people most. What was your best adventure/program/vacation?   \n",
       "212  It does not take Sherlock Holmes to work out that if a rich father employs accountants or financial advisers to produce figures that indicate that he does not have the financial wherewithal to pay maintenance to his children , there is a possibility that some fiddles will be going on . Where financial advisers and accountants are employed to suggest that a father can not afford to pay maintenance for his children , surely there should be another system to check whether something may be wrong ?   \n",
       "340                                                                                                                                           If the Home Secretary is not willing to consider handing the police in London over to an elected authority , will he consider handing them over to at least a partly elected authority , in line with the discussions going on about other powers in the context of the GLC abolition Bill being considered in the other place between Ministers and Conservative peers ?   \n",
       "401                                                                                                                                                                                                                                                                                                                                      Do you think you're enjoying tennis again? It seemed after you won the French Open there was a lot of pressure; last year you had a tough match here. Are you feeling happier?   \n",
       "375                                                                                              As the Gray report refers to major procurement activities , will the Minister tell me , and the House , what recent discussions he has had with commanders on the ground about the effectiveness of personal protection equipment for our troops in theatre - such as the Stourbridge war hero , 19-year - old Michelle Norris , who risked her life and was the first woman to gain the military cross for her work ?   \n",
       "\n",
       "    answer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \\\n",
       "279                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The first time I went to an actually nice beach after growing up going to the beaches on the Gulf of Mexico.   \n",
       "212  Family insecurity is now as important as economic insecurity as a force for poverty and disadvantage . We have new policies on child support , which we aim to implement as soon as possible . We are driving up the rate of payment—in terms of the cash that is now due , some 70 per cent . or more of maintenance is now paid . There remain some non - resident parents or absent fathers , however—perhaps 30 per cent.—who are not paying maintenance . The purpose of our new reforms is to spend less time on complicated assessment , in a move towards simplicity , and more time on enforcement . It is crucial that we undertake that as soon as possible .   \n",
       "340                                                                                                                                      Since returning from the United States , I have tried to play a full part in alerting the public to the problem of the glut of cocaine available in South America and likely to be diverted from the American to the British market . Already , a considerable response has been evident , notably in the formation of two customs teams specifically to deal with cocaine . Cocaine seizures this year are much higher than they were last year . That is a measure of success , but we intend to be diligent on this vital topic .   \n",
       "401                                                                                                                                                                                                                                                                                                                                             I think, yes, yes. At least until beginning of 2013 until now I didn't waste the if I have match point, I didn't win the match, so... I think it's very tough, you know, because when I was playing Cirstea in Rod Laver, I was thinking about the match last year. Something you couldn't forget. Always in your mind, yeah.   \n",
       "375                                                                                                                                                                                   Of course I noticed that rather startling figure when I read the Gray report myself . The right hon Gentleman , who has obviously read the report , will also have noticed that there is no evidential basis for that statement anywhere in it , nor is there an evidential basis for it anywhere else that I have ever come across . The very fact that the figure ranges between £ 1 billion and more than £ 2 billion shows , I think , how imprecise that statement inevitably is .   \n",
       "\n",
       "     label  \n",
       "279  2      \n",
       "212  0      \n",
       "340  0      \n",
       "401  2      \n",
       "375  0      "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuning_datasets[\"question_avoidance_preprocessed_dataset\"].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b06bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['question_avoidance_preprocessed_dataset']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available datasets:\", list(finetuning_datasets.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc04ff",
   "metadata": {},
   "source": [
    "#### Initialize mlflow\n",
    "\n",
    "To launch the ui:\n",
    "\n",
    "```shell\n",
    "poetry run mlflow ui\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23aaeb87-a51e-4546-8858-ef81d6ff9e25",
   "metadata": {
    "id": "23aaeb87-a51e-4546-8858-ef81d6ff9e25"
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Question Dodging - Zero Shot MNLI\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# autologging\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a792a",
   "metadata": {},
   "source": [
    "#### Set up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a875d44c-8724-48d5-ba77-a80f792e8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:15:22.153930: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-19 15:15:22.170722: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    print(gpus)\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \"\"\"\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    \"\"\";\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc5207",
   "metadata": {},
   "source": [
    "It's important to reformulate the premise and hypothesis fed into the model. Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4903aa6-735d-452a-a2c4-371357ef53e0",
   "metadata": {
    "id": "a4903aa6-735d-452a-a2c4-371357ef53e0"
   },
   "source": [
    "#### Load zero-shot model\n",
    "\n",
    "There is a number of zero-shot classification models that could be used. \n",
    "\n",
    "One example is [typeform/distilbert-base-uncased-mnli](https://huggingface.co/typeform/distilbert-base-uncased-mnli). It supports TF/Keras as well and performs okay-ish.\n",
    "\n",
    "Other good options:\n",
    "- https://huggingface.co/facebook/bart-large-mnli (for English only)\n",
    "- https://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli (outperforms other models)\n",
    "- https://huggingface.co/joeddav/xlm-roberta-large-xnli (multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3445ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653c0318-1f0e-4a03-a582-68c5876f89b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "653c0318-1f0e-4a03-a582-68c5876f89b9",
    "outputId": "b5e5aa70-e68c-4ec0-d7fb-f6ae18ffd9ed",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "model_name = \"typeform/distilbert-base-uncased-mnli\"\n",
    "#model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "#model_name = \"roberta-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "num_labels = len(config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"typeform/distilbert-base-uncased-mnli\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"finetuning_task\": \"mnli\",\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"ENTAILMENT\",\n",
       "    \"1\": \"NEUTRAL\",\n",
       "    \"2\": \"CONTRADICTION\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"CONTRADICTION\": 2,\n",
       "    \"ENTAILMENT\": 0,\n",
       "    \"NEUTRAL\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.35.0\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f10a62-4b31-4c5a-88e7-e3f2fb5a3bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21f10a62-4b31-4c5a-88e7-e3f2fb5a3bd3",
    "outputId": "d3a8af59-5479-4350-8d45-69231839e2ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=config.id2label,\n",
    "    label2id=config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955779 (255.42 MB)\n",
      "Trainable params: 66955779 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7ff43c15feb0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8cd4b-80ff-4d51-83c4-c6d762b72d7c",
   "metadata": {
    "id": "aea8cd4b-80ff-4d51-83c4-c6d762b72d7c"
   },
   "source": [
    "#### Load preprocesssed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61248b97-7864-4cf8-ad92-e52d8320830e",
   "metadata": {
    "id": "61248b97-7864-4cf8-ad92-e52d8320830e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Does my hon Friend agree that the export tariff of 3p per kWh for households should be increased ?</td>\n",
       "      <td>The coalition agreement commits the Government to a huge increase in energy from waste through anaerobic digestion , and to that end we brought the industry together in a meeting on 6 July , together with colleagues from Department for Environment , Food and Rural Affairs and the Department for Communities and Local Government , to drive the agenda forward . It is early days for the feed - in tariff scheme generally , and as we know it is a new scheme . I am fully aware of the specific problems with farm - based anaerobic digesters , which the hon Gentleman raised , and I am commissioning further technical work in my Department to try to deal with them .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>MAZZTER WHATS UP BRO\\n\\nI know I've played a lot with you before but I don't remember where. Does the name Applebottom James or Bart Arkdukus Farnum ring a bell with you?</td>\n",
       "      <td>No. :(\\n\\nI have been on the 2fort2furious servers a lot though.\\n\\nMore recently they're a bit dead so I sometimes join a Lotus 24/7 2fort server for fun.  Or random servers that look fun.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Is it the case that the delivery unit monitors between four and six targets in each of the policy areas of health , education , transport and law and order , selected from the Departments ' public service agreements ? Will the Minister tell us which particular targets are selected at the moment ? Perhaps he could give us examples and put a note in the Library so that we can know what all the targets are and what the future priorities will be .</td>\n",
       "      <td>I am grateful to my hon Friend for those observations . Given my background in the Department of Trade and Industry , I am fully aware of the important work being done on getting services online . I am also aware that some of the most innovative and exciting work has been done at local government level . That is why I , with responsibility for e - transformation , will work closely with colleagues at the newly configured centre to ensure that we learn from what is best in local government and take the opportunity share best practice across the country .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question                                                                                                                                                                                                                                                                                                                                                                                                                                                          \\\n",
       "351                                                                                                                                                                                                                                                                                                                                                               Does my hon Friend agree that the export tariff of 3p per kWh for households should be increased ?   \n",
       "170                                                                                                                                                                                                                                                                                      MAZZTER WHATS UP BRO\\n\\nI know I've played a lot with you before but I don't remember where. Does the name Applebottom James or Bart Arkdukus Farnum ring a bell with you?    \n",
       "361  Is it the case that the delivery unit monitors between four and six targets in each of the policy areas of health , education , transport and law and order , selected from the Departments ' public service agreements ? Will the Minister tell us which particular targets are selected at the moment ? Perhaps he could give us examples and put a note in the Library so that we can know what all the targets are and what the future priorities will be .   \n",
       "\n",
       "    answer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \\\n",
       "351  The coalition agreement commits the Government to a huge increase in energy from waste through anaerobic digestion , and to that end we brought the industry together in a meeting on 6 July , together with colleagues from Department for Environment , Food and Rural Affairs and the Department for Communities and Local Government , to drive the agenda forward . It is early days for the feed - in tariff scheme generally , and as we know it is a new scheme . I am fully aware of the specific problems with farm - based anaerobic digesters , which the hon Gentleman raised , and I am commissioning further technical work in my Department to try to deal with them .   \n",
       "170                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           No. :(\\n\\nI have been on the 2fort2furious servers a lot though.\\n\\nMore recently they're a bit dead so I sometimes join a Lotus 24/7 2fort server for fun.  Or random servers that look fun.   \n",
       "361                                                                                                         I am grateful to my hon Friend for those observations . Given my background in the Department of Trade and Industry , I am fully aware of the important work being done on getting services online . I am also aware that some of the most innovative and exciting work has been done at local government level . That is why I , with responsibility for e - transformation , will work closely with colleagues at the newly configured centre to ensure that we learn from what is best in local government and take the opportunity share best practice across the country .   \n",
       "\n",
       "     label  \n",
       "351  0      \n",
       "170  2      \n",
       "361  0      "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets = [finetuning_datasets[dataset] for dataset in finetuning_datasets]\n",
    "data = pd.concat(list_of_datasets)\n",
    "\n",
    "del finetuning_datasets\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "[[-2.7766745  4.1372247 -1.8948877]]\n",
      "NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "example = tokenizer(\"Question: Are you here? Answer: I'm just an engineer\", \"This answer dodges the question\", add_special_tokens=True, padding=True, truncation=\"only_first\", return_attention_mask=True)\n",
    "\n",
    "prediction = model.predict(example[\"input_ids\"])\n",
    "print(prediction.logits)\n",
    "print(config.id2label[np.argmax(prediction.logits)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960e060",
   "metadata": {},
   "source": [
    "One could use the `train_test_split` method from `datasets` ([source](https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes)) which readily splits a dataset object to a train and test set, but using the sklearn one makes it easier to get a train, test, and validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e53ac346-1f09-489b-a5ce-6f8decb70a5d",
   "metadata": {
    "id": "e53ac346-1f09-489b-a5ce-6f8decb70a5d"
   },
   "outputs": [],
   "source": [
    "X = data[[\"question\", \"answer\"]]\n",
    "y = data[[\"label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0de5bae6-7170-4a65-9f07-0f664e9ce4a1",
   "metadata": {
    "id": "0de5bae6-7170-4a65-9f07-0f664e9ce4a1"
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "test_dataset = pd.concat([X_test, y_test], axis=1)\n",
    "val_dataset = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec6a9d7d-3fd6-4225-b09c-63a3b67cd082",
   "metadata": {
    "id": "ec6a9d7d-3fd6-4225-b09c-63a3b67cd082"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_dataset, preserve_index=False)\n",
    "val_dataset = Dataset.from_pandas(val_dataset, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154011f-ff99-45ea-a8d6-a2b1e2027ed9",
   "metadata": {
    "id": "4154011f-ff99-45ea-a8d6-a2b1e2027ed9"
   },
   "outputs": [],
   "source": [
    "#del data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9879668-21cd-4c55-8c1c-877e3ff0735a",
   "metadata": {
    "id": "a9879668-21cd-4c55-8c1c-877e3ff0735a"
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset, \"val\": val_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee5e49c3-bd9e-4fd5-85fa-222ce8ad6aa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee5e49c3-bd9e-4fd5-85fa-222ce8ad6aa0",
    "outputId": "f8441a5d-4f19-47e9-deda-5fc39cd7b41b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'label'],\n",
       "        num_rows: 253\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'label'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['question', 'answer', 'label'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On a slightly lighter note, what do you think makes a good definitive fist pump: the quiet steely determination or fullon adrenaline spin your arms around?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"question\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955779 (255.42 MB)\n",
      "Trainable params: 66955779 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469eac3c",
   "metadata": {},
   "source": [
    "#### Preprocessing the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b54119bb-34de-4cdd-a5f0-4c6125e3ee31",
   "metadata": {
    "id": "b54119bb-34de-4cdd-a5f0-4c6125e3ee31"
   },
   "outputs": [],
   "source": [
    "premise_template = Template(\"Question: $question. Answer: $answer\")\n",
    "hypothesis_template = Template(\"In this example, the answer evades or ignores the question.\")\n",
    "\n",
    "mlflow.log_params({\n",
    "        \"premise_template\": premise_template.safe_substitute(),\n",
    "        \"hypothesis_template\": hypothesis_template.safe_substitute(),\n",
    "        \"input_note\": \"passed as premise, hypothesis\" # \"passed into tokenizer as [premise, hypothesis]\" \n",
    "    }\n",
    ")\n",
    "\n",
    "def preprocess_function(row, train=True):\n",
    "    premise = premise_template.safe_substitute(question = row['question'], answer = row['answer'])\n",
    "    hypothesis = hypothesis_template.safe_substitute()\n",
    "\n",
    "    encoded = tokenizer(premise, hypothesis, add_special_tokens=True, padding=True, truncation=\"only_first\", return_attention_mask=True)\n",
    "    #encoded = tokenizer(premise, hypothesis, add_special_tokens=True,  truncation=\"only_first\", return_attention_mask=True, return_tensors=\"tf\")# padding=True,\n",
    "    #return_tensors=\"np\")\n",
    "    if train:\n",
    "        encoded[\"labels\"] = row[\"label\"]\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 3160, 1024, 2024, 2017, 2503, 1996, 2160, 1012, 3437, 1024, 2021, 1045, 1005, 1049, 2074, 2019, 3992, 102, 1999, 2023, 2742, 1010, 1996, 3437, 26399, 2015, 2030, 26663, 1996, 3160, 1012, 102]\n",
      "<class 'list'>\n",
      "{'input_ids': [101, 3160, 1024, 2024, 2017, 2503, 1996, 2160, 1012, 3437, 1024, 2021, 1045, 1005, 1049, 2074, 2019, 3992, 102, 1999, 2023, 2742, 1010, 1996, 3437, 26399, 2015, 2030, 26663, 1996, 3160, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "example = preprocess_function({\"question\": \"Are you inside the house\", \"answer\": \"But I'm just an engineer\"}, train=False)\n",
    "\n",
    "print(example[\"input_ids\"])\n",
    "print(type(example[\"input_ids\"]))\n",
    "print(example)\n",
    "#print(tokenizer.decode(example.input_ids))\n",
    "#print(example.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] question : are you inside the house. answer : but i'm just an engineer [SEP] in this example, the answer evades or ignores the question. [SEP]\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-2.0722811  4.369235  -3.2038815]], shape=(1, 3), dtype=float32)\n",
      "NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "example_output = model(np.array(example[\"input_ids\"]))\n",
    "print(example_output.logits)\n",
    "print(config.id2label[np.argmax(example_output.logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8d74ef2-b874-4922-82be-4d533d88aeb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "2c6eee62bb5f43f0ab5445e2545350bb",
      "4282a71f1ff44ae1b7a9bcf19a9249fa",
      "d88138bb5ed649489170652dce08a395",
      "b4972818e14d4651afc2bf843640af50",
      "107eada8d9664199896149bdeb2b14ec",
      "7756ca6b6d214e2ab5d06d430ca82db2",
      "bb1c2f534f44470d83a27dc68874d863",
      "6b4e031b53af40af838ee40390029393",
      "68b5225be3234e849f1dc36427dbe4f4",
      "062bda6c84cf4c9fad7e2050a25fc33c",
      "973853ef47ba411abbce6dc0ddb709bd",
      "5e587aa13909470db10d5790bfa009ae",
      "3c2db12d171b4ad9a8f5ae66d89a836c",
      "ab8199c72a0b4571b4b8673fbe97bacc",
      "3bfb081bc6954cdf81980ef06b8466a4",
      "84e1893eef574970970a9b8e1f202542",
      "bea2cafe1a6d4b349ddbd7c065a81eae",
      "2d9d982a49b149e4805cc4889e5d7792",
      "662233903ad84ec2b2dca184394ed647",
      "366ee0a00c9c48fcb050ac2cdc4019cb",
      "90b3c6d23da44a719416a766e7da363f",
      "cfe1c4d17e4947e8a7e01412dc57b59f",
      "c806d364eac54dc4bc7a6be5943df324",
      "5b804c8d76cc461290b0486fe25ba877",
      "ed45b17493e449258168e1514e56c8ad",
      "2f2670e00de44a6a92c49dfffdf37c1c",
      "6a27cf046c374913a7ff3829cd8a646e",
      "4fc7f539b9f549ab8761e8969d322146",
      "19cd89538d9e444a89b15f00893c6df3",
      "fc1a8332a0024bd7b49951c49f6c207b",
      "aad9d03b7d7b45d19d32dd9d368e331c",
      "4b7f256364f74fc69f570720ac3a8321",
      "f675b12842cb4b1a81bbaf07185424e9"
     ]
    },
    "id": "e8d74ef2-b874-4922-82be-4d533d88aeb8",
    "outputId": "231aa80a-612b-45e8-ee73-46176863a824"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6754a63a14ee4bc3ad41b728c6872819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1692f0c2e36b4fe3a04b5dc5f9b2692c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333d955b90794155946aa73e36fa11d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, remove_columns=[\"question\", \"answer\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a657602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(dtype='int64', id=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].features[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "023f5b5d-6cb5-4a12-987a-6ff1dcdfae5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "023f5b5d-6cb5-4a12-987a-6ff1dcdfae5c",
    "outputId": "ad5ec466-1d15-4d84-dbf2-30069d52a1ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 253\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] question : on a slightly lighter note, what do you think makes a good definitive fist pump : the quiet steely determination or fullon adrenaline spin your arms around?. answer : ( laughter. ) i think i have a few different versions. [SEP] in this example, the answer evades or ignores the question. [SEP]'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_dataset[\"train\"][\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2562d4fd-68c3-441f-9757-b8b2fda7ce31",
   "metadata": {
    "id": "2562d4fd-68c3-441f-9757-b8b2fda7ce31"
   },
   "outputs": [],
   "source": [
    "# a helper function to show the prediction results\n",
    "\n",
    "def get_results(outputs, model, return_all_scores=True):\n",
    "    scores = np.exp(outputs) / np.exp(outputs).sum(-1, keepdims=True)\n",
    "    if return_all_scores:\n",
    "        return [\n",
    "            [{\"label\": model.config.id2label[i], \"score\": score.item()} for i, score in enumerate(item)]\n",
    "                for item in scores\n",
    "            ]\n",
    "    else:\n",
    "        return [\n",
    "            {\"label\": model.config.id2label[item.argmax()], \"score\": item.max().item()} for item in scores\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5a9f1d3-5c72-4f31-a5a8-f596b15620f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5a9f1d3-5c72-4f31-a5a8-f596b15620f0",
    "outputId": "3019b385-a641-4334-c45b-bfc0a4360a3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "dataset_batch_size = 4 # 16\n",
    "\n",
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tf_validation_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"val\"],\n",
    "    shuffle=False,\n",
    "    batch_size=dataset_batch_size,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "tf_test_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=dataset_batch_size,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d321cbdd-8b8d-4a8c-b203-8c5ece9a7785",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d321cbdd-8b8d-4a8c-b203-8c5ece9a7785",
    "outputId": "c7e409ae-bcc9-4947-b1be-4f27f0c482c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(4, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(4, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(4,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the dataset is ready to be fed into the model to fit\n",
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38309816-db14-40e2-8889-5f71b17c8bd9",
   "metadata": {
    "id": "38309816-db14-40e2-8889-5f71b17c8bd9"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "number_of_training_examples = tf_train_dataset.cardinality().numpy()\n",
    "batches_per_epoch = number_of_training_examples // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-4, num_warmup_steps=0, num_train_steps=total_train_steps, weight_decay_rate=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0940d79e-1099-4536-9d2e-01cd5c46b59a",
   "metadata": {
    "id": "0940d79e-1099-4536-9d2e-01cd5c46b59a"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer) # run_eagerly=True, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The issue was that BatchEncoding objects are not accepted, they need to be converted into a dict first\n",
    "# https://github.com/huggingface/transformers/issues/20709\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "553b543a-d5c9-4f39-8ed3-bba2fc5a630c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "553b543a-d5c9-4f39-8ed3-bba2fc5a630c",
    "outputId": "3c668416-ed7f-44a1-e6ca-4b02dee441e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 7s 268ms/step - loss: 3.3095\n"
     ]
    }
   ],
   "source": [
    "# evaluating loss before finetuning the model on our \"target data\"\n",
    "before_finetuning_history = model.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22945b34-61a4-4396-9e1f-93125fa3f16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22945b34-61a4-4396-9e1f-93125fa3f16c",
    "outputId": "35909442-eb6b-4216-9576-910d9552d8ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.src.metrics.base_metric.Mean object at 0x7ff337d1e4d0>]\n",
      "3.3094873428344727\n"
     ]
    }
   ],
   "source": [
    "# we are looking at Mean loss\n",
    "print(model.metrics)\n",
    "print(before_finetuning_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"loss before finetuning\", before_finetuning_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75298b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snek/a-politicians-answer/notebooks/text_classification_model_save is already a clone of https://huggingface.co/i-be-snek/question-dodging-finetuned-distilbert-base-uncased-mnli. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "# remember to install git-lfs\n",
    "# !apt install git-lfs\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "#metric = model.metrics[0]\n",
    "\n",
    "metric = load(\"glue\", \"mnli\")\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=compute_metrics, eval_dataset=tf_validation_dataset\n",
    ")\n",
    "\n",
    "push_to_hub_model_id = \"question-dodging-finetuned-distilbert-base-uncased-mnli\"\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./text_classification_model_save/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"./text_classification_model_save\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_model_id=push_to_hub_model_id,\n",
    ")\n",
    "\n",
    "callbacks = [metric_callback, tensorboard_callback] #, push_to_hub_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_gpu_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0462c12-e832-42ee-8753-9bccc5e9b53d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0462c12-e832-42ee-8753-9bccc5e9b53d",
    "outputId": "08cbc2f4-72cb-45e8-a0c5-ca839177e8af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/19 15:21:43 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: The layer \"tf_distil_bert_for_sequence_classification\" has never been called and thus has no defined input shape. Note that the `input_shape` property is only available for Functional and Sequential models.\n",
      "2023/12/19 15:21:44 WARNING mlflow.data.tensorflow_dataset: Failed to infer schema for TensorFlow dataset. Exception: Failed to infer schema for tf.data.Dataset. Schemas can only be inferred if the dataset consists of tensors. Ragged tensors, tensor arrays, and other types are not supported. Additionally, datasets with nested tensors are not supported.\n",
      "2023/12/19 15:21:44 WARNING mlflow.data.tensorflow_dataset: Failed to infer schema for TensorFlow dataset. Exception: Failed to infer schema for tf.data.Dataset. Schemas can only be inferred if the dataset consists of tensors. Ragged tensors, tensor arrays, and other types are not supported. Additionally, datasets with nested tensors are not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 82s 1s/step - loss: 1.2514 - val_loss: 0.8746 - accuracy: 0.5647\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.8439 - val_loss: 0.8442 - accuracy: 0.6353\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.7683 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.7656 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.7609 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 78s 1s/step - loss: 0.7598 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 74s 1s/step - loss: 0.7669 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 77s 1s/step - loss: 0.7653 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.7615 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 76s 1s/step - loss: 0.7636 - val_loss: 0.8413 - accuracy: 0.6353\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7ff422cd6740>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7ff422fe0760>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7ff422fe33a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7ff422fc6020>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7ff422fb0ca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7ff422fb38e0>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp743_abzq/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp743_abzq/model/data/model/assets\n",
      "2023/12/19 15:34:42 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp743_abzq/model, flavor: tensorflow), fall back to return ['tensorflow==2.14.0']. Set logging level to DEBUG to see the full traceback.\n",
      "2023/12/19 15:34:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        tf_train_dataset,\n",
    "        validation_data=tf_validation_dataset,\n",
    "        epochs=num_epochs,\n",
    "        #batch_size=2,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e67c14a6-de23-4a0c-b2e6-832f34498d85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e67c14a6-de23-4a0c-b2e6-832f34498d85",
    "outputId": "49a3c893-9786-40c2-b30f-800f4b203a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 6s 257ms/step - loss: 0.7331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7330948114395142"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_finetuning_history = model.evaluate(tf_test_dataset)\n",
    "after_finetuning_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.26290268 -0.4130244   0.45110038]], shape=(1, 3), dtype=float32)\n",
      "CONTRADICTION\n"
     ]
    }
   ],
   "source": [
    "example_output = model(np.array(example[\"input_ids\"]))\n",
    "print(example_output.logits)\n",
    "print(config.id2label[np.argmax(example_output.logits)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] question : are you inside the house. answer : but i'm just an engineer [SEP] in this example, the answer evades or ignores the question. [SEP]\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example[\"input_ids\"])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "062bda6c84cf4c9fad7e2050a25fc33c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "107eada8d9664199896149bdeb2b14ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19cd89538d9e444a89b15f00893c6df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c6eee62bb5f43f0ab5445e2545350bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4282a71f1ff44ae1b7a9bcf19a9249fa",
       "IPY_MODEL_d88138bb5ed649489170652dce08a395",
       "IPY_MODEL_b4972818e14d4651afc2bf843640af50"
      ],
      "layout": "IPY_MODEL_107eada8d9664199896149bdeb2b14ec"
     }
    },
    "2d9d982a49b149e4805cc4889e5d7792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f2670e00de44a6a92c49dfffdf37c1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b7f256364f74fc69f570720ac3a8321",
      "placeholder": "​",
      "style": "IPY_MODEL_f675b12842cb4b1a81bbaf07185424e9",
      "value": " 83/83 [00:00&lt;00:00, 380.54 examples/s]"
     }
    },
    "366ee0a00c9c48fcb050ac2cdc4019cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bfb081bc6954cdf81980ef06b8466a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90b3c6d23da44a719416a766e7da363f",
      "placeholder": "​",
      "style": "IPY_MODEL_cfe1c4d17e4947e8a7e01412dc57b59f",
      "value": " 83/83 [00:00&lt;00:00, 382.09 examples/s]"
     }
    },
    "3c2db12d171b4ad9a8f5ae66d89a836c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bea2cafe1a6d4b349ddbd7c065a81eae",
      "placeholder": "​",
      "style": "IPY_MODEL_2d9d982a49b149e4805cc4889e5d7792",
      "value": "Map: 100%"
     }
    },
    "4282a71f1ff44ae1b7a9bcf19a9249fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7756ca6b6d214e2ab5d06d430ca82db2",
      "placeholder": "​",
      "style": "IPY_MODEL_bb1c2f534f44470d83a27dc68874d863",
      "value": "Map: 100%"
     }
    },
    "4b7f256364f74fc69f570720ac3a8321": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fc7f539b9f549ab8761e8969d322146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b804c8d76cc461290b0486fe25ba877": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fc7f539b9f549ab8761e8969d322146",
      "placeholder": "​",
      "style": "IPY_MODEL_19cd89538d9e444a89b15f00893c6df3",
      "value": "Map: 100%"
     }
    },
    "5e587aa13909470db10d5790bfa009ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c2db12d171b4ad9a8f5ae66d89a836c",
       "IPY_MODEL_ab8199c72a0b4571b4b8673fbe97bacc",
       "IPY_MODEL_3bfb081bc6954cdf81980ef06b8466a4"
      ],
      "layout": "IPY_MODEL_84e1893eef574970970a9b8e1f202542"
     }
    },
    "662233903ad84ec2b2dca184394ed647": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68b5225be3234e849f1dc36427dbe4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a27cf046c374913a7ff3829cd8a646e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4e031b53af40af838ee40390029393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7756ca6b6d214e2ab5d06d430ca82db2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84e1893eef574970970a9b8e1f202542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90b3c6d23da44a719416a766e7da363f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "973853ef47ba411abbce6dc0ddb709bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aad9d03b7d7b45d19d32dd9d368e331c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab8199c72a0b4571b4b8673fbe97bacc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_662233903ad84ec2b2dca184394ed647",
      "max": 83,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_366ee0a00c9c48fcb050ac2cdc4019cb",
      "value": 83
     }
    },
    "b4972818e14d4651afc2bf843640af50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_062bda6c84cf4c9fad7e2050a25fc33c",
      "placeholder": "​",
      "style": "IPY_MODEL_973853ef47ba411abbce6dc0ddb709bd",
      "value": " 247/247 [00:00&lt;00:00, 492.02 examples/s]"
     }
    },
    "bb1c2f534f44470d83a27dc68874d863": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bea2cafe1a6d4b349ddbd7c065a81eae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c806d364eac54dc4bc7a6be5943df324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b804c8d76cc461290b0486fe25ba877",
       "IPY_MODEL_ed45b17493e449258168e1514e56c8ad",
       "IPY_MODEL_2f2670e00de44a6a92c49dfffdf37c1c"
      ],
      "layout": "IPY_MODEL_6a27cf046c374913a7ff3829cd8a646e"
     }
    },
    "cfe1c4d17e4947e8a7e01412dc57b59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d88138bb5ed649489170652dce08a395": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b4e031b53af40af838ee40390029393",
      "max": 247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68b5225be3234e849f1dc36427dbe4f4",
      "value": 247
     }
    },
    "ed45b17493e449258168e1514e56c8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc1a8332a0024bd7b49951c49f6c207b",
      "max": 83,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aad9d03b7d7b45d19d32dd9d368e331c",
      "value": 83
     }
    },
    "f675b12842cb4b1a81bbaf07185424e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc1a8332a0024bd7b49951c49f6c207b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
