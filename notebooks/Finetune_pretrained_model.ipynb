{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c367521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# \n",
    "# notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d7fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.utils import send_example_telemetry\n",
    "# send_example_telemetry(\"language_modeling_notebook_finetuning_nli\", framework=\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "380dc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of problems with the gpu memory\n",
    "def clear_gpu_mem(): \n",
    "    from numba import cuda \n",
    "    device = cuda.get_current_device()\n",
    "    device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9ad57a-ef76-4c9c-828e-918d9afe2ffc",
   "metadata": {
    "id": "7c9ad57a-ef76-4c9c-828e-918d9afe2ffc"
   },
   "source": [
    "#### Load finetuning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bee734-9884-4fd1-ad70-decb33927b5f",
   "metadata": {
    "id": "42bee734-9884-4fd1-ad70-decb33927b5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 10:02:02.557071: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-16 10:02:02.588023: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-16 10:02:02.588049: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-16 10:02:02.588068: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-16 10:02:02.593890: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # for more convenient data splitting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import Dataset, DatasetDict # to create Dataset objects\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "# import mlflow # for ml tracking\n",
    "\n",
    "from string import Template # to template the premise and hypothesis for the NLI task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91a647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"colheader_justify\", \"left\")\n",
    "\n",
    "path = \"../data\"\n",
    "dataset_files = [\"question_avoidance_preprocessed_dataset.parquet\"]\n",
    "finetuning_datasets = {}\n",
    "for i in dataset_files:\n",
    "    finetuning_datasets[i.split(\".parquet\")[0]] = pd.read_parquet(f\"{path}/{i}\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03b06bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['question_avoidance_preprocessed_dataset']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available datasets:\", list(finetuning_datasets.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc04ff",
   "metadata": {},
   "source": [
    "#### Initialize mlflow\n",
    "\n",
    "To launch the ui:\n",
    "\n",
    "```shell\n",
    "poetry run mlflow ui\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23aaeb87-a51e-4546-8858-ef81d6ff9e25",
   "metadata": {
    "id": "23aaeb87-a51e-4546-8858-ef81d6ff9e25"
   },
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(\"Question Dodging 1 (different input format)\")\n",
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# \n",
    "# # autologging\n",
    "# mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a792a",
   "metadata": {},
   "source": [
    "#### Set up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a875d44c-8724-48d5-ba77-a80f792e8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 10:02:09.668634: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-11-16 10:02:09.668657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: snek\n",
      "2023-11-16 10:02:09.668661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: snek\n",
      "2023-11-16 10:02:09.668756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.113.1\n",
      "2023-11-16 10:02:09.668767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.113.1\n",
      "2023-11-16 10:02:09.668769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.113.1\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    print(gpus)\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    \"\"\"\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    \"\"\";\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc5207",
   "metadata": {},
   "source": [
    "It's important to reformulate the premise and hypothesis fed into the model. Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4903aa6-735d-452a-a2c4-371357ef53e0",
   "metadata": {
    "id": "a4903aa6-735d-452a-a2c4-371357ef53e0"
   },
   "source": [
    "#### Load zero-shot model\n",
    "\n",
    "There is a number of zero-shot classification models that could be used. \n",
    "\n",
    "One example is [typeform/distilbert-base-uncased-mnli](https://huggingface.co/typeform/distilbert-base-uncased-mnli). It supports TF/Keras as well and performs okay-ish.\n",
    "\n",
    "Other good options:\n",
    "- https://huggingface.co/facebook/bart-large-mnli (for English only)\n",
    "- https://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli (outperforms other models)\n",
    "- https://huggingface.co/joeddav/xlm-roberta-large-xnli (multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3445ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "653c0318-1f0e-4a03-a582-68c5876f89b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "653c0318-1f0e-4a03-a582-68c5876f89b9",
    "outputId": "b5e5aa70-e68c-4ec0-d7fb-f6ae18ffd9ed",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "model_name = \"typeform/distilbert-base-uncased-mnli\"\n",
    "# model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "#model_name = \"roberta-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "num_labels = len(config.id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21f10a62-4b31-4c5a-88e7-e3f2fb5a3bd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21f10a62-4b31-4c5a-88e7-e3f2fb5a3bd3",
    "outputId": "d3a8af59-5479-4350-8d45-69231839e2ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=config.id2label,\n",
    "    label2id=config.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955779 (255.42 MB)\n",
      "Trainable params: 66955779 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer at 0x7f3ac83dfa30>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8cd4b-80ff-4d51-83c4-c6d762b72d7c",
   "metadata": {
    "id": "aea8cd4b-80ff-4d51-83c4-c6d762b72d7c"
   },
   "source": [
    "#### Load preprocesssed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61248b97-7864-4cf8-ad92-e52d8320830e",
   "metadata": {
    "id": "61248b97-7864-4cf8-ad92-e52d8320830e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>As the Gray report refers to major procurement activities , will the Minister tell me , and the House , what recent discussions he has had with commanders on the ground about the effectiveness of personal protection equipment for our troops in theatre - such as the Stourbridge war hero , 19-year - old Michelle Norris , who risked her life and was the first woman to gain the military cross for her work ?</td>\n",
       "      <td>Of course I noticed that rather startling figure when I read the Gray report myself . The right hon Gentleman , who has obviously read the report , will also have noticed that there is no evidential basis for that statement anywhere in it , nor is there an evidential basis for it anywhere else that I have ever come across . The very fact that the figure ranges between £ 1 billion and more than £ 2 billion shows , I think , how imprecise that statement inevitably is .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>How important is this result for the clay season that comes now and Roland Garros?</td>\n",
       "      <td>Oh, any title is big, and it means a lot, I mean, such a big tournament that is considered one of the biggest tournaments in our sport. I won three times here. I think that says enough about how I feel playing in Miami. I love the crowd. It's a lot of support. Night sessions are my most preferable here, because the crowd gets into it and you can feel that great vibe in the stands. I have been really playing well in the last couple of years here, so this is going to be very encouraging for me prior to the clay court season. I'm gonna have more confidence coming into the MonteCarlo tournament. It's going to be the opening tournament on clay. I haven't played it last year. I look forward to it. I want to start well. I want to start strong. I want to go deep in the tournament, and, you know, there is a lot of tournaments coming up. Obviously Roland Garros, Olympics, Wimbledon, they are top of the priority list, but still, I want to perform well on all the others.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>As the steeply rising unemployment level is the worst problem facing the country and the Government , why has not the right hon Lady and her Government brought before the House , before Parliament departs for the recess , fresh proposals to restore the £ 170 million cut that they made in the Manpower Services Commission budget ? When will they carry out and bring before the House an expanded programme to deal with this problem ? Will the right hon Lady now tell us , when the Government have failed to bring forward a programme before the departure of Parliament for the recess , how soon those proposals will be announced to the nation ?</td>\n",
       "      <td>Already , about 324,000 people are affected by and benefit from special employment and training measures . My right hon Friend the Secretary of State for Employment has given an undertaking that if the youth opportunities programme is not sufficient it will be enlarged , so that every school leaver has the offer of a place by Easter 1981 .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \\\n",
       "375                                                                                                                                                                                                                                              As the Gray report refers to major procurement activities , will the Minister tell me , and the House , what recent discussions he has had with commanders on the ground about the effectiveness of personal protection equipment for our troops in theatre - such as the Stourbridge war hero , 19-year - old Michelle Norris , who risked her life and was the first woman to gain the military cross for her work ?   \n",
       "236                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  How important is this result for the clay season that comes now and Roland Garros?   \n",
       "114  As the steeply rising unemployment level is the worst problem facing the country and the Government , why has not the right hon Lady and her Government brought before the House , before Parliament departs for the recess , fresh proposals to restore the £ 170 million cut that they made in the Manpower Services Commission budget ? When will they carry out and bring before the House an expanded programme to deal with this problem ? Will the right hon Lady now tell us , when the Government have failed to bring forward a programme before the departure of Parliament for the recess , how soon those proposals will be announced to the nation ?   \n",
       "\n",
       "    answer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \\\n",
       "375                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Of course I noticed that rather startling figure when I read the Gray report myself . The right hon Gentleman , who has obviously read the report , will also have noticed that there is no evidential basis for that statement anywhere in it , nor is there an evidential basis for it anywhere else that I have ever come across . The very fact that the figure ranges between £ 1 billion and more than £ 2 billion shows , I think , how imprecise that statement inevitably is .   \n",
       "236  Oh, any title is big, and it means a lot, I mean, such a big tournament that is considered one of the biggest tournaments in our sport. I won three times here. I think that says enough about how I feel playing in Miami. I love the crowd. It's a lot of support. Night sessions are my most preferable here, because the crowd gets into it and you can feel that great vibe in the stands. I have been really playing well in the last couple of years here, so this is going to be very encouraging for me prior to the clay court season. I'm gonna have more confidence coming into the MonteCarlo tournament. It's going to be the opening tournament on clay. I haven't played it last year. I look forward to it. I want to start well. I want to start strong. I want to go deep in the tournament, and, you know, there is a lot of tournaments coming up. Obviously Roland Garros, Olympics, Wimbledon, they are top of the priority list, but still, I want to perform well on all the others.   \n",
       "114                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Already , about 324,000 people are affected by and benefit from special employment and training measures . My right hon Friend the Secretary of State for Employment has given an undertaking that if the youth opportunities programme is not sufficient it will be enlarged , so that every school leaver has the offer of a place by Easter 1981 .   \n",
       "\n",
       "     label  \n",
       "375  0      \n",
       "236  2      \n",
       "114  0      "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_datasets = [finetuning_datasets[dataset] for dataset in finetuning_datasets]\n",
    "data = pd.concat(list_of_datasets)\n",
    "\n",
    "del finetuning_datasets\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960e060",
   "metadata": {},
   "source": [
    "One could use the `train_test_split` method from `datasets` ([source](https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes)) which readily splits a dataset object to a train and test set, but using the sklearn one makes it easier to get a train, test, and validation split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e53ac346-1f09-489b-a5ce-6f8decb70a5d",
   "metadata": {
    "id": "e53ac346-1f09-489b-a5ce-6f8decb70a5d"
   },
   "outputs": [],
   "source": [
    "X = data[[\"question\", \"answer\"]]\n",
    "y = data[[\"label\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de5bae6-7170-4a65-9f07-0f664e9ce4a1",
   "metadata": {
    "id": "0de5bae6-7170-4a65-9f07-0f664e9ce4a1"
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.concat([X_train, y_train], axis=1)\n",
    "test_dataset = pd.concat([X_test, y_test], axis=1)\n",
    "val_dataset = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec6a9d7d-3fd6-4225-b09c-63a3b67cd082",
   "metadata": {
    "id": "ec6a9d7d-3fd6-4225-b09c-63a3b67cd082"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_dataset, preserve_index=False)\n",
    "val_dataset = Dataset.from_pandas(val_dataset, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4154011f-ff99-45ea-a8d6-a2b1e2027ed9",
   "metadata": {
    "id": "4154011f-ff99-45ea-a8d6-a2b1e2027ed9"
   },
   "outputs": [],
   "source": [
    "#del data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9879668-21cd-4c55-8c1c-877e3ff0735a",
   "metadata": {
    "id": "a9879668-21cd-4c55-8c1c-877e3ff0735a"
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset, \"val\": val_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee5e49c3-bd9e-4fd5-85fa-222ce8ad6aa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee5e49c3-bd9e-4fd5-85fa-222ce8ad6aa0",
    "outputId": "f8441a5d-4f19-47e9-deda-5fc39cd7b41b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'label'],\n",
       "        num_rows: 253\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'label'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['question', 'answer', 'label'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On a slightly lighter note, what do you think makes a good definitive fist pump: the quiet steely determination or fullon adrenaline spin your arms around?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"question\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  2307      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955779 (255.42 MB)\n",
      "Trainable params: 66955779 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469eac3c",
   "metadata": {},
   "source": [
    "#### Preprocessing the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54119bb-34de-4cdd-a5f0-4c6125e3ee31",
   "metadata": {
    "id": "b54119bb-34de-4cdd-a5f0-4c6125e3ee31"
   },
   "outputs": [],
   "source": [
    "premise_template = Template(\"Question: $question. Answer: $answer\")\n",
    "hypothesis_template = Template(\"In this example, the answer evades or ignores the question.\")\n",
    "\n",
    "# mlflow.log_params(\n",
    "#     {\n",
    "#         \"premise_template\": premise_template.safe_substitute(),\n",
    "#         \"hypothesis_template\": hypothesis_template.safe_substitute(),\n",
    "#         \"input_note\": \"passed as premise, hypothesis\" # \"passed into tokenizer as [premise, hypothesis]\" \n",
    "#     }\n",
    "# )\n",
    "\n",
    "def preprocess_function(row, train=True):\n",
    "    #premise = f\"Question: {row['premise']}\"\n",
    "    #hypothesis = f\"This answer evades the question: {row['hypothesis']}\"\n",
    "    premise = premise_template.safe_substitute(question = row['question'], answer = row['answer'])\n",
    "    hypothesis = hypothesis_template.safe_substitute()\n",
    "    encoded = tokenizer(premise, hypothesis, add_special_tokens=True, padding=True, truncation=\"only_first\", return_attention_mask=True, return_tensors=\"np\") #, return_tensors=\"tf\") # truncation=True,  padding=True, \n",
    "    if train:\n",
    "        encoded[\"labels\"] = row[\"label\"]\n",
    "    #print(encoded)\n",
    "    #print(encoded)\n",
    "    # encoded[\"input_sentence\"] = tokenizer.decode(encoded.input_ids) #[0])\n",
    "    #encoded[\"input_sentence\"] = tokenizer.decode(encoded.input_ids)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[ 101, 2023, 2003, 2070, 7953,  102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1]])}\n",
      "\n",
      "{'input_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[ 101, 2023, 2003, 2070, 7953,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1]], dtype=int32)>}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_input_np = tokenizer(\"This is some input\", return_tensors=\"np\")\n",
    "tokenized_input_tf = tokenizer(\"This is some input\", return_tensors=\"tf\")\n",
    "# tokenized_input_pt = tokenizer(\"This is some input\", return_tensors=\"pt\")\n",
    "\n",
    "inputs = [tokenized_input_np, tokenized_input_tf]# , tokenized_input_pt]\n",
    "\n",
    "for i in inputs:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[ 101, 2023, 2003, 2070, 7953,  102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[ 3.2404332, -1.1141715, -4.125758 ]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_np = model(tokenized_input_np)\n",
    "print(tokenized_input_np)\n",
    "outputs_np.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[ 101, 2023, 2003, 2070, 7953,  102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1]], dtype=int32)>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[ 3.2404332, -1.1141715, -4.125758 ]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(tokenized_input_tf)\n",
    "print(tokenized_input_tf)\n",
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "tokenizer.model_input_names\n",
    "\n",
    "#model_inputs = {k: k for k in tokenizer.model_input_names}\n",
    "pprint.pprint(tokenizer.model_input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35190006-dd3f-4968-abea-7136ccd70a3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35190006-dd3f-4968-abea-7136ccd70a3f",
    "outputId": "0fe15684-4741-4571-d695-a9ba92c18706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  101  3160  1024  2006  1037  3621  9442  3602  1010  2054  2079  2017\n",
      "   2228  3084  1037  2204 15764  7345 10216  1024  1996  4251  3886  2100\n",
      "   9128  2030  2440  2239 14963  6714  2115  2608  2105  1029  1012  3437\n",
      "   1024  1006  7239  1012  1007  1045  2228  1045  2031  1037  2261  2367\n",
      "   4617  1012   102  1999  2023  2742  1010  1996  3437 26399  2015  2030\n",
      "  26663  1996  3160  1012   102]]\n",
      "[CLS] question : on a slightly lighter note, what do you think makes a good definitive fist pump : the quiet steely determination or fullon adrenaline spin your arms around?. answer : ( laughter. ) i think i have a few different versions. [SEP] in this example, the answer evades or ignores the question. [SEP]\n",
      "{'input_ids': array([[  101,  3160,  1024,  2006,  1037,  3621,  9442,  3602,  1010,\n",
      "         2054,  2079,  2017,  2228,  3084,  1037,  2204, 15764,  7345,\n",
      "        10216,  1024,  1996,  4251,  3886,  2100,  9128,  2030,  2440,\n",
      "         2239, 14963,  6714,  2115,  2608,  2105,  1029,  1012,  3437,\n",
      "         1024,  1006,  7239,  1012,  1007,  1045,  2228,  1045,  2031,\n",
      "         1037,  2261,  2367,  4617,  1012,   102,  1999,  2023,  2742,\n",
      "         1010,  1996,  3437, 26399,  2015,  2030, 26663,  1996,  3160,\n",
      "         1012,   102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': 0}\n"
     ]
    }
   ],
   "source": [
    "example = preprocess_function(dataset[\"train\"][0])\n",
    "print(example.input_ids)\n",
    "print(tokenizer.decode(example.input_ids[0]))\n",
    "#print(tokenizer.decode(example.input_ids[1]))\n",
    "#print(tokenizer.decode(example.input_ids))\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8d74ef2-b874-4922-82be-4d533d88aeb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "2c6eee62bb5f43f0ab5445e2545350bb",
      "4282a71f1ff44ae1b7a9bcf19a9249fa",
      "d88138bb5ed649489170652dce08a395",
      "b4972818e14d4651afc2bf843640af50",
      "107eada8d9664199896149bdeb2b14ec",
      "7756ca6b6d214e2ab5d06d430ca82db2",
      "bb1c2f534f44470d83a27dc68874d863",
      "6b4e031b53af40af838ee40390029393",
      "68b5225be3234e849f1dc36427dbe4f4",
      "062bda6c84cf4c9fad7e2050a25fc33c",
      "973853ef47ba411abbce6dc0ddb709bd",
      "5e587aa13909470db10d5790bfa009ae",
      "3c2db12d171b4ad9a8f5ae66d89a836c",
      "ab8199c72a0b4571b4b8673fbe97bacc",
      "3bfb081bc6954cdf81980ef06b8466a4",
      "84e1893eef574970970a9b8e1f202542",
      "bea2cafe1a6d4b349ddbd7c065a81eae",
      "2d9d982a49b149e4805cc4889e5d7792",
      "662233903ad84ec2b2dca184394ed647",
      "366ee0a00c9c48fcb050ac2cdc4019cb",
      "90b3c6d23da44a719416a766e7da363f",
      "cfe1c4d17e4947e8a7e01412dc57b59f",
      "c806d364eac54dc4bc7a6be5943df324",
      "5b804c8d76cc461290b0486fe25ba877",
      "ed45b17493e449258168e1514e56c8ad",
      "2f2670e00de44a6a92c49dfffdf37c1c",
      "6a27cf046c374913a7ff3829cd8a646e",
      "4fc7f539b9f549ab8761e8969d322146",
      "19cd89538d9e444a89b15f00893c6df3",
      "fc1a8332a0024bd7b49951c49f6c207b",
      "aad9d03b7d7b45d19d32dd9d368e331c",
      "4b7f256364f74fc69f570720ac3a8321",
      "f675b12842cb4b1a81bbaf07185424e9"
     ]
    },
    "id": "e8d74ef2-b874-4922-82be-4d533d88aeb8",
    "outputId": "231aa80a-612b-45e8-ee73-46176863a824"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03b366a0a8a4d1e9c4a705dd85bdf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/253 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234e894db27d43e3ace6f63634920426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74c77ffe7d94a0a974c5d9445c182c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/85 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, remove_columns=[\"question\", \"answer\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7a657602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(dtype='int64', id=None)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].features[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "023f5b5d-6cb5-4a12-987a-6ff1dcdfae5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "023f5b5d-6cb5-4a12-987a-6ff1dcdfae5c",
    "outputId": "ad5ec466-1d15-4d84-dbf2-30069d52a1ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 253\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] question : on a slightly lighter note, what do you think makes a good definitive fist pump : the quiet steely determination or fullon adrenaline spin your arms around?. answer : ( laughter. ) i think i have a few different versions. [SEP] in this example, the answer evades or ignores the question. [SEP]'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_dataset[\"train\"][\"input_ids\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2562d4fd-68c3-441f-9757-b8b2fda7ce31",
   "metadata": {
    "id": "2562d4fd-68c3-441f-9757-b8b2fda7ce31"
   },
   "outputs": [],
   "source": [
    "# a helper function to show the prediction results\n",
    "\n",
    "def get_results(outputs, model, return_all_scores=True):\n",
    "    scores = np.exp(outputs) / np.exp(outputs).sum(-1, keepdims=True)\n",
    "    if return_all_scores:\n",
    "        return [\n",
    "            [{\"label\": model.config.id2label[i], \"score\": score.item()} for i, score in enumerate(item)]\n",
    "                for item in scores\n",
    "            ]\n",
    "    else:\n",
    "        return [\n",
    "            {\"label\": model.config.id2label[item.argmax()], \"score\": item.max().item()} for item in scores\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5a9f1d3-5c72-4f31-a5a8-f596b15620f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5a9f1d3-5c72-4f31-a5a8-f596b15620f0",
    "outputId": "3019b385-a641-4334-c45b-bfc0a4360a3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "dataset_batch_size = 4 # 16\n",
    "\n",
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=dataset_batch_size,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tf_validation_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"val\"],\n",
    "    shuffle=False,\n",
    "    batch_size=dataset_batch_size,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "tf_test_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=dataset_batch_size,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d321cbdd-8b8d-4a8c-b203-8c5ece9a7785",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d321cbdd-8b8d-4a8c-b203-8c5ece9a7785",
    "outputId": "c7e409ae-bcc9-4947-b1be-4f27f0c482c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(4, 1, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(4, 1, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(4,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the dataset is ready to be fed into the model to fit\n",
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1065fbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(4, 1, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(4, 1, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(4,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34f50ace-ae3b-4470-9e91-28efc4122423",
   "metadata": {
    "id": "34f50ace-ae3b-4470-9e91-28efc4122423"
   },
   "outputs": [],
   "source": [
    "# del encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38309816-db14-40e2-8889-5f71b17c8bd9",
   "metadata": {
    "id": "38309816-db14-40e2-8889-5f71b17c8bd9"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "batch_size = 4\n",
    "num_epochs = 5\n",
    "number_of_training_examples = tf_train_dataset.cardinality().numpy()\n",
    "batches_per_epoch = number_of_training_examples // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0940d79e-1099-4536-9d2e-01cd5c46b59a",
   "metadata": {
    "id": "0940d79e-1099-4536-9d2e-01cd5c46b59a"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer) # run_eagerly=True, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[ 101, 2023, 2003, 2070, 7953,  102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1]])}\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# The issue was that BatchEncoding objects are not accepted, they need to be converted into a dict first\n",
    "# https://github.com/huggingface/transformers/issues/20709\n",
    "\n",
    "sample, label = dict(tokenized_input_np), np.array([0])\n",
    "print(sample)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 101, 2023, 2003, 2070, 7953,  102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.013389784842729568"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(sample, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[  101,  3160,  1024,  2024,  2017,  2045,  1029,  1012,  3437,\n",
      "         1024,  1045,  1005,  1049,  2025,  2469,   102,  1999,  2023,\n",
      "         2742,  1010,  1996,  3437, 26399,  2015,  2030, 26663,  1996,\n",
      "         3160,  1012,   102]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': array(1)}\n",
      "[CLS] question : are you there?. answer : i'm not sure [SEP] in this example, the answer evades or ignores the question. [SEP]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_input = preprocess_function({\"question\": \"Are you there?\", \"answer\": \"I'm not sure\", \"label\": np.array(1)})\n",
    "print(preprocessed_input)\n",
    "print(tokenizer.decode(preprocessed_input.input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00531332], dtype=float32)>, logits=<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-1.6558033,  3.8010535, -3.047937 ]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preprocessed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 5.4622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.462170600891113"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate({\"input_ids\": preprocessed_input[\"input_ids\"], \"attention_mask\": preprocessed_input[\"attention_mask\"]}, np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "553b543a-d5c9-4f39-8ed3-bba2fc5a630c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "553b543a-d5c9-4f39-8ed3-bba2fc5a630c",
    "outputId": "3c668416-ed7f-44a1-e6ca-4b02dee441e5"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1679, in run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3269, in call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 4067, in _call_for_each_replica\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1747, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 589, in __call__\n        return super().__call__(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/tmp/__autograph_generated_fileobfu4ug3.py\", line 37, in tf__run_call_with_unpacked_inputs  **\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/tmp/__autograph_generated_file2ugw3a3y.py\", line 17, in tf__call  **\n        distilbert_output = ag__.converted_call(ag__.ld(self).distilbert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/tmp/__autograph_generated_fileobfu4ug3.py\", line 37, in tf__run_call_with_unpacked_inputs  **\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/tmp/__autograph_generated_fileikv16pe2.py\", line 93, in tf__call  **\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/tmp/__autograph_generated_filez7t8wf0l.py\", line 54, in tf__call  **\n        final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n        ndims = len(input_shape)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n        raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n\n    ValueError: Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 720, in call  *\n            distilbert_output = self.distilbert(\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n            raise new_e.with_traceback(e.__traceback__) from None\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n            return fn(*args, **kwargs)\n        File \"/tmp/__autograph_generated_fileobfu4ug3.py\", line 37, in tf__run_call_with_unpacked_inputs  **\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"/tmp/__autograph_generated_fileikv16pe2.py\", line 93, in tf__call  **\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n            raise new_e.with_traceback(e.__traceback__) from None\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n            return fn(*args, **kwargs)\n        File \"/tmp/__autograph_generated_filez7t8wf0l.py\", line 54, in tf__call  **\n            final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n            raise new_e.with_traceback(e.__traceback__) from None\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n            ndims = len(input_shape)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n            raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n    \n        ValueError: Exception encountered when calling layer 'distilbert' (type TFDistilBertMainLayer).\n        \n        in user code:\n        \n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 402, in call  *\n                embedding_output = self.embeddings(input_ids, inputs_embeds=inputs_embeds)  # (bs, seq_length, dim)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n                return fn(*args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n                outputs = call_fn(inputs, *args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n                raise new_e.with_traceback(e.__traceback__) from None\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n                return fn(*args, **kwargs)\n            File \"/tmp/__autograph_generated_filez7t8wf0l.py\", line 54, in tf__call  **\n                final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n                return fn(*args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n                outputs = call_fn(inputs, *args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n                raise new_e.with_traceback(e.__traceback__) from None\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n                return fn(*args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n                ndims = len(input_shape)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n                raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n        \n            ValueError: Exception encountered when calling layer 'embeddings' (type TFEmbeddings).\n            \n            in user code:\n            \n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 124, in call  *\n                    final_embeddings = self.LayerNorm(inputs=final_embeddings)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n                    return fn(*args, **kwargs)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n                    outputs = call_fn(inputs, *args, **kwargs)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n                    raise new_e.with_traceback(e.__traceback__) from None\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n                    return fn(*args, **kwargs)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n                    ndims = len(input_shape)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n                    raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n            \n                ValueError: Exception encountered when calling layer 'LayerNorm' (type LayerNormalization).\n                \n                Cannot take the length of shape with unknown rank.\n                \n                Call arguments received by layer 'LayerNorm' (type LayerNormalization):\n                  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n            \n            \n            Call arguments received by layer 'embeddings' (type TFEmbeddings):\n              • input_ids=tf.Tensor(shape=<unknown>, dtype=int32)\n              • position_ids=None\n              • inputs_embeds=None\n              • training=False\n        \n        \n        Call arguments received by layer 'distilbert' (type TFDistilBertMainLayer):\n          • input_ids=tf.Tensor(shape=<unknown>, dtype=int32)\n          • attention_mask=tf.Tensor(shape=<unknown>, dtype=int32)\n          • head_mask=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received by layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification):\n      • input_ids={'input_ids': 'tf.Tensor(shape=<unknown>, dtype=int64)', 'attention_mask': 'tf.Tensor(shape=<unknown>, dtype=int64)', 'labels': 'tf.Tensor(shape=(None,), dtype=int64)'}\n      • attention_mask=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/snek/a-politicians-answer/notebooks/Finetune_pretrained_model.ipynb Cell 57\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/a-politicians-answer/notebooks/Finetune_pretrained_model.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m1\u001b[39m\u001b[39m# evaluating loss before finetuning the model on our \"target data\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/snek/a-politicians-answer/notebooks/Finetune_pretrained_model.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m before_finetuning_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(tf_test_dataset)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2269\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2270\u001b[0m             ):\n\u001b[1;32m   2271\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2272\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2273\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2274\u001b[0m                     data_handler,\n\u001b[1;32m   2275\u001b[0m                     step,\n\u001b[1;32m   2276\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2277\u001b[0m                 )\n\u001b[1;32m   2279\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2280\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4079\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4080\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4081\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:141\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_traceback_filtering_enabled():\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m   \u001b[39m# In some very rare cases,\u001b[39;00m\n\u001b[1;32m    144\u001b[0m   \u001b[39m# `is_traceback_filtering_enabled` (from the outer scope) may not be\u001b[39;00m\n\u001b[1;32m    145\u001b[0m   \u001b[39m# accessible from inside this function\u001b[39;00m\n\u001b[1;32m    146\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    877\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    878\u001b[0m )\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[39m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, tracing_options\u001b[39m=\u001b[39;49mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:284\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 284\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    285\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[1;32m    290\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    291\u001b[0m   )\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:308\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m    304\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    305\u001b[0m       placeholder_context\n\u001b[1;32m    306\u001b[0m   )\n\u001b[0;32m--> 308\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    309\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    310\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mpython_function,\n\u001b[1;32m    311\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49margs,\n\u001b[1;32m    312\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49mkwargs,\n\u001b[1;32m    313\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    314\u001b[0m     func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    315\u001b[0m     arg_names\u001b[39m=\u001b[39;49mfunction_type_utils\u001b[39m.\u001b[39;49mto_arg_names(function_type),\n\u001b[1;32m    316\u001b[0m     create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    319\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    321\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileju6i2jze.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:2025\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   2021\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     )\n\u001b[1;32m   2024\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 2025\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   2026\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   2027\u001b[0m     outputs,\n\u001b[1;32m   2028\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   2029\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   2030\u001b[0m )\n\u001b[1;32m   2031\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1679\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1675\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1678\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1679\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3269\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3267\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3268\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3269\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4067\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4065\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4066\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 4067\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:2013\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 2013\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtest_step(data)\n\u001b[1;32m   2014\u001b[0m     \u001b[39m# Ensure counter is updated only if `test_step` succeeds.\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1747\u001b[0m, in \u001b[0;36mTFPreTrainedModel.test_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, return_loss\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1747\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_using_dummy_loss:\n\u001b[1;32m   1749\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(y_pred\u001b[39m.\u001b[39mloss, y_pred\u001b[39m.\u001b[39mloss, sample_weight, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:589\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    587\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 589\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:155\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         new_e \u001b[39m=\u001b[39m e\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\u001b[39m.\u001b[39mwith_traceback(e\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[39mdel\u001b[39;00m signature\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileobfu4ug3.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(func), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m),), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(unpacked_inputs)), fscope)\n\u001b[1;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file2ugw3a3y.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m     15\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 17\u001b[0m distilbert_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mdistilbert, (), \u001b[39mdict\u001b[39;49m(input_ids\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(input_ids), attention_mask\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(attention_mask), head_mask\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(head_mask), inputs_embeds\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs_embeds), output_attentions\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(output_attentions), output_hidden_states\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(output_hidden_states), return_dict\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(return_dict), training\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(training)), fscope)\n\u001b[1;32m     18\u001b[0m hidden_state \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(distilbert_output)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m pooled_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(hidden_state)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:155\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         new_e \u001b[39m=\u001b[39m e\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\u001b[39m.\u001b[39mwith_traceback(e\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[39mdel\u001b[39;00m signature\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileobfu4ug3.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(func), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m),), \u001b[39mdict\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(unpacked_inputs)), fscope)\n\u001b[1;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileikv16pe2.py:93\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m     91\u001b[0m     head_mask \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mnum_hidden_layers\n\u001b[1;32m     92\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(head_mask) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, if_body_4, else_body_4, get_state_4, set_state_4, (\u001b[39m'\u001b[39m\u001b[39mhead_mask\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m embedding_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49membeddings, (ag__\u001b[39m.\u001b[39;49mld(input_ids),), \u001b[39mdict\u001b[39;49m(inputs_embeds\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(inputs_embeds)), fscope)\n\u001b[1;32m     94\u001b[0m tfmr_output \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtransformer, (ag__\u001b[39m.\u001b[39mld(embedding_output), ag__\u001b[39m.\u001b[39mld(attention_mask), ag__\u001b[39m.\u001b[39mld(head_mask), ag__\u001b[39m.\u001b[39mld(output_attentions), ag__\u001b[39m.\u001b[39mld(output_hidden_states), ag__\u001b[39m.\u001b[39mld(return_dict)), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(training)), fscope)\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:155\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         new_e \u001b[39m=\u001b[39m e\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\u001b[39m.\u001b[39mwith_traceback(e\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[39mdel\u001b[39;00m signature\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filez7t8wf0l.py:54\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, position_ids, inputs_embeds, training)\u001b[0m\n\u001b[1;32m     52\u001b[0m position_embeds \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mgather, (), \u001b[39mdict\u001b[39m(params\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mposition_embeddings, indices\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(position_ids)), fscope)\n\u001b[1;32m     53\u001b[0m final_embeddings \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(inputs_embeds) \u001b[39m+\u001b[39m ag__\u001b[39m.\u001b[39mld(position_embeds)\n\u001b[0;32m---> 54\u001b[0m final_embeddings \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mLayerNorm, (), \u001b[39mdict\u001b[39;49m(inputs\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(final_embeddings)), fscope)\n\u001b[1;32m     55\u001b[0m final_embeddings \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdropout, (), \u001b[39mdict\u001b[39m(inputs\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(final_embeddings), training\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(training)), fscope)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:61\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mdebugging\u001b[39m.\u001b[39mis_traceback_filtering_enabled():\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     63\u001b[0m     filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:155\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         new_e \u001b[39m=\u001b[39m e\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\u001b[39m.\u001b[39mwith_traceback(e\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[39mdel\u001b[39;00m signature\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py:263\u001b[0m, in \u001b[0;36mLayerNormalization.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m# Compute the axes along which to reduce the mean / variance\u001b[39;00m\n\u001b[1;32m    262\u001b[0m input_shape \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 263\u001b[0m ndims \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(input_shape)\n\u001b[1;32m    265\u001b[0m \u001b[39m# Broadcasting only necessary for norm when the axis is not just\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m# the last dimension\u001b[39;00m\n\u001b[1;32m    267\u001b[0m broadcast_shape \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m ndims\n",
      "File \u001b[0;32m~/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:918\u001b[0m, in \u001b[0;36mTensorShape.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the rank of this shape, or raises ValueError if unspecified.\"\"\"\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dims \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot take the length of shape with unknown rank.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    919\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dims)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2025, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1679, in run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3269, in call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 4067, in _call_for_each_replica\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2013, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 1747, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 589, in __call__\n        return super().__call__(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/tmp/__autograph_generated_fileobfu4ug3.py\", line 37, in tf__run_call_with_unpacked_inputs  **\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/tmp/__autograph_generated_file2ugw3a3y.py\", line 17, in tf__call  **\n        distilbert_output = ag__.converted_call(ag__.ld(self).distilbert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/tmp/__autograph_generated_fileobfu4ug3.py\", line 37, in tf__run_call_with_unpacked_inputs  **\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/tmp/__autograph_generated_fileikv16pe2.py\", line 93, in tf__call  **\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/tmp/__autograph_generated_filez7t8wf0l.py\", line 54, in tf__call  **\n        final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n        raise new_e.with_traceback(e.__traceback__) from None\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n        return fn(*args, **kwargs)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n        ndims = len(input_shape)\n    File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n        raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n\n    ValueError: Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 720, in call  *\n            distilbert_output = self.distilbert(\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n            raise new_e.with_traceback(e.__traceback__) from None\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n            return fn(*args, **kwargs)\n        File \"/tmp/__autograph_generated_fileobfu4ug3.py\", line 37, in tf__run_call_with_unpacked_inputs  **\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"/tmp/__autograph_generated_fileikv16pe2.py\", line 93, in tf__call  **\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n            raise new_e.with_traceback(e.__traceback__) from None\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n            return fn(*args, **kwargs)\n        File \"/tmp/__autograph_generated_filez7t8wf0l.py\", line 54, in tf__call  **\n            final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n            outputs = call_fn(inputs, *args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n            raise new_e.with_traceback(e.__traceback__) from None\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n            return fn(*args, **kwargs)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n            ndims = len(input_shape)\n        File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n            raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n    \n        ValueError: Exception encountered when calling layer 'distilbert' (type TFDistilBertMainLayer).\n        \n        in user code:\n        \n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 402, in call  *\n                embedding_output = self.embeddings(input_ids, inputs_embeds=inputs_embeds)  # (bs, seq_length, dim)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n                return fn(*args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n                outputs = call_fn(inputs, *args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n                raise new_e.with_traceback(e.__traceback__) from None\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n                return fn(*args, **kwargs)\n            File \"/tmp/__autograph_generated_filez7t8wf0l.py\", line 54, in tf__call  **\n                final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n                return fn(*args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n                outputs = call_fn(inputs, *args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n                raise new_e.with_traceback(e.__traceback__) from None\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n                return fn(*args, **kwargs)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n                ndims = len(input_shape)\n            File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n                raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n        \n            ValueError: Exception encountered when calling layer 'embeddings' (type TFEmbeddings).\n            \n            in user code:\n            \n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/transformers/models/distilbert/modeling_tf_distilbert.py\", line 124, in call  *\n                    final_embeddings = self.LayerNorm(inputs=final_embeddings)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 61, in error_handler  **\n                    return fn(*args, **kwargs)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n                    outputs = call_fn(inputs, *args, **kwargs)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 155, in error_handler\n                    raise new_e.with_traceback(e.__traceback__) from None\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n                    return fn(*args, **kwargs)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/keras/src/layers/normalization/layer_normalization.py\", line 263, in call  **\n                    ndims = len(input_shape)\n                File \"/home/snek/a-politicians-answer/.venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py\", line 918, in __len__\n                    raise ValueError(\"Cannot take the length of shape with unknown rank.\")\n            \n                ValueError: Exception encountered when calling layer 'LayerNorm' (type LayerNormalization).\n                \n                Cannot take the length of shape with unknown rank.\n                \n                Call arguments received by layer 'LayerNorm' (type LayerNormalization):\n                  • inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n            \n            \n            Call arguments received by layer 'embeddings' (type TFEmbeddings):\n              • input_ids=tf.Tensor(shape=<unknown>, dtype=int32)\n              • position_ids=None\n              • inputs_embeds=None\n              • training=False\n        \n        \n        Call arguments received by layer 'distilbert' (type TFDistilBertMainLayer):\n          • input_ids=tf.Tensor(shape=<unknown>, dtype=int32)\n          • attention_mask=tf.Tensor(shape=<unknown>, dtype=int32)\n          • head_mask=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received by layer 'tf_distil_bert_for_sequence_classification_1' (type TFDistilBertForSequenceClassification):\n      • input_ids={'input_ids': 'tf.Tensor(shape=<unknown>, dtype=int64)', 'attention_mask': 'tf.Tensor(shape=<unknown>, dtype=int64)', 'labels': 'tf.Tensor(shape=(None,), dtype=int64)'}\n      • attention_mask=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=None\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "1# evaluating loss before finetuning the model on our \"target data\"\n",
    "before_finetuning_history = model.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22945b34-61a4-4396-9e1f-93125fa3f16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22945b34-61a4-4396-9e1f-93125fa3f16c",
    "outputId": "35909442-eb6b-4216-9576-910d9552d8ce"
   },
   "outputs": [],
   "source": [
    "# we are looking at Mean loss\n",
    "print(model.metrics)\n",
    "print(before_finetuning_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"loss before finetuning\", before_finetuning_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9139b-2e13-4509-8906-463b906af925",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab9139b-2e13-4509-8906-463b906af925",
    "outputId": "9f2b844f-28b5-47cd-ef46-497c89d01742"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75298b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "# remember to install git-lfs\n",
    "# !apt install git-lfs\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "#metric = model.metrics[0]\n",
    "\n",
    "metric = load(\"glue\", \"mnli\")\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=compute_metrics, eval_dataset=tf_validation_dataset\n",
    ")\n",
    "\n",
    "push_to_hub_model_id = \"question-dodging-finetuned-distilbert-base-uncased-mnli\"\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./text_classification_model_save/logs\")\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"./text_classification_model_save\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_model_id=push_to_hub_model_id,\n",
    ")\n",
    "\n",
    "callbacks = [metric_callback, tensorboard_callback, push_to_hub_callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear_gpu_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0462c12-e832-42ee-8753-9bccc5e9b53d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0462c12-e832-42ee-8753-9bccc5e9b53d",
    "outputId": "08cbc2f4-72cb-45e8-a0c5-ca839177e8af"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "        tf_train_dataset,\n",
    "        validation_data=tf_validation_dataset,\n",
    "        epochs=num_epochs,\n",
    "        batch_size=2,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c14a6-de23-4a0c-b2e6-832f34498d85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e67c14a6-de23-4a0c-b2e6-832f34498d85",
    "outputId": "49a3c893-9786-40c2-b30f-800f4b203a91"
   },
   "outputs": [],
   "source": [
    "after_finetuning_history = model.evaluate(tf_test_dataset)\n",
    "after_finetuning_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_example = preprocess_function({\"question\": \"Who am I?\", \"answer\": \"not me\"}, False)\n",
    "input_example[\"labels\"] = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_exmaple = tokenizer(\"What are you doing here? Not sure\", return_attention_mask=True)\n",
    "tokenized_exmaple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tokenized_exmaple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "062bda6c84cf4c9fad7e2050a25fc33c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "107eada8d9664199896149bdeb2b14ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19cd89538d9e444a89b15f00893c6df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c6eee62bb5f43f0ab5445e2545350bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4282a71f1ff44ae1b7a9bcf19a9249fa",
       "IPY_MODEL_d88138bb5ed649489170652dce08a395",
       "IPY_MODEL_b4972818e14d4651afc2bf843640af50"
      ],
      "layout": "IPY_MODEL_107eada8d9664199896149bdeb2b14ec"
     }
    },
    "2d9d982a49b149e4805cc4889e5d7792": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f2670e00de44a6a92c49dfffdf37c1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b7f256364f74fc69f570720ac3a8321",
      "placeholder": "​",
      "style": "IPY_MODEL_f675b12842cb4b1a81bbaf07185424e9",
      "value": " 83/83 [00:00&lt;00:00, 380.54 examples/s]"
     }
    },
    "366ee0a00c9c48fcb050ac2cdc4019cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bfb081bc6954cdf81980ef06b8466a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90b3c6d23da44a719416a766e7da363f",
      "placeholder": "​",
      "style": "IPY_MODEL_cfe1c4d17e4947e8a7e01412dc57b59f",
      "value": " 83/83 [00:00&lt;00:00, 382.09 examples/s]"
     }
    },
    "3c2db12d171b4ad9a8f5ae66d89a836c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bea2cafe1a6d4b349ddbd7c065a81eae",
      "placeholder": "​",
      "style": "IPY_MODEL_2d9d982a49b149e4805cc4889e5d7792",
      "value": "Map: 100%"
     }
    },
    "4282a71f1ff44ae1b7a9bcf19a9249fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7756ca6b6d214e2ab5d06d430ca82db2",
      "placeholder": "​",
      "style": "IPY_MODEL_bb1c2f534f44470d83a27dc68874d863",
      "value": "Map: 100%"
     }
    },
    "4b7f256364f74fc69f570720ac3a8321": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fc7f539b9f549ab8761e8969d322146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b804c8d76cc461290b0486fe25ba877": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fc7f539b9f549ab8761e8969d322146",
      "placeholder": "​",
      "style": "IPY_MODEL_19cd89538d9e444a89b15f00893c6df3",
      "value": "Map: 100%"
     }
    },
    "5e587aa13909470db10d5790bfa009ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c2db12d171b4ad9a8f5ae66d89a836c",
       "IPY_MODEL_ab8199c72a0b4571b4b8673fbe97bacc",
       "IPY_MODEL_3bfb081bc6954cdf81980ef06b8466a4"
      ],
      "layout": "IPY_MODEL_84e1893eef574970970a9b8e1f202542"
     }
    },
    "662233903ad84ec2b2dca184394ed647": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68b5225be3234e849f1dc36427dbe4f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a27cf046c374913a7ff3829cd8a646e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4e031b53af40af838ee40390029393": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7756ca6b6d214e2ab5d06d430ca82db2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84e1893eef574970970a9b8e1f202542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90b3c6d23da44a719416a766e7da363f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "973853ef47ba411abbce6dc0ddb709bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aad9d03b7d7b45d19d32dd9d368e331c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab8199c72a0b4571b4b8673fbe97bacc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_662233903ad84ec2b2dca184394ed647",
      "max": 83,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_366ee0a00c9c48fcb050ac2cdc4019cb",
      "value": 83
     }
    },
    "b4972818e14d4651afc2bf843640af50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_062bda6c84cf4c9fad7e2050a25fc33c",
      "placeholder": "​",
      "style": "IPY_MODEL_973853ef47ba411abbce6dc0ddb709bd",
      "value": " 247/247 [00:00&lt;00:00, 492.02 examples/s]"
     }
    },
    "bb1c2f534f44470d83a27dc68874d863": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bea2cafe1a6d4b349ddbd7c065a81eae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c806d364eac54dc4bc7a6be5943df324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b804c8d76cc461290b0486fe25ba877",
       "IPY_MODEL_ed45b17493e449258168e1514e56c8ad",
       "IPY_MODEL_2f2670e00de44a6a92c49dfffdf37c1c"
      ],
      "layout": "IPY_MODEL_6a27cf046c374913a7ff3829cd8a646e"
     }
    },
    "cfe1c4d17e4947e8a7e01412dc57b59f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d88138bb5ed649489170652dce08a395": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b4e031b53af40af838ee40390029393",
      "max": 247,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68b5225be3234e849f1dc36427dbe4f4",
      "value": 247
     }
    },
    "ed45b17493e449258168e1514e56c8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc1a8332a0024bd7b49951c49f6c207b",
      "max": 83,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aad9d03b7d7b45d19d32dd9d368e331c",
      "value": 83
     }
    },
    "f675b12842cb4b1a81bbaf07185424e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc1a8332a0024bd7b49951c49f6c207b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
